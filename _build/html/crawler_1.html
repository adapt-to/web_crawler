

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>1. 爬虫基础 &mdash; WebCrawler 1.0.0 documentation</title>
  

  
  
  
  

  

  
  
    

  

  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="prev" title="0. 写在前面" href="forword.html" /> 

  
  <script src="_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="index.html" class="icon icon-home"> WebCrawler
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="forword.html">0. 写在前面</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">1. 爬虫基础</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#httphttps">HTTP和HTTPS</a></li>
<li class="toctree-l2"><a class="reference internal" href="#uri-url-urn">URI-URL-URN区别</a></li>
<li class="toctree-l2"><a class="reference internal" href="#http">HTTP的请求过程</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#request">请求 (Request)</a></li>
<li class="toctree-l3"><a class="reference internal" href="#response">响应 (Response)</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#id2">网页基础</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id3">网页的组成</a></li>
<li class="toctree-l3"><a class="reference internal" href="#html-dom">HTML DOM</a></li>
<li class="toctree-l3"><a class="reference internal" href="#css">CSS选择器</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#id5">爬虫的基本原理</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id6">爬虫的步骤</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#sessioncookies">Session和Cookies</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id7">静态网页与动态网页</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id8">Session和Cookies原理</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id9">会话维持</a></li>
<li class="toctree-l3"><a class="reference internal" href="#cooikes">Cooikes属性结构</a></li>
<li class="toctree-l3"><a class="reference internal" href="#cooikescooikes">会话Cooikes和持久Cooikes</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#id10">代理</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id11">什么是代理</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id12">代理的作用</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id13">代理分类</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id14">根据协议分类</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id15">根据匿名程度分类</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">WebCrawler</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html">Docs</a> &raquo;</li>
        
      <li>1. 爬虫基础</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/crawler_1.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="id1">
<h1>1. 爬虫基础<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h1>
<blockquote>
<div>————如果把互联网比作成一张大网，那么爬虫就是获取到网页提取并保存其中的信息的自动化 <strong>程序</strong></div></blockquote>
<p>在认识爬虫之前，还需要具备的一些基础的网络知识</p>
<hr class="docutils" />
<div class="section" id="httphttps">
<h2>HTTP和HTTPS<a class="headerlink" href="#httphttps" title="Permalink to this headline">¶</a></h2>
<p>在浏览器中网页的url开头中经常会见到http或者https。
http和https都是访问资源时需要的 <strong>协议类型</strong>，除此之外还有一些其他协议如：ftp、sftp、smb等</p>
<div class="line-block">
<div class="line">HTTP：<strong>超文本传输协议</strong>。顾名思义，此协议是从网络传输超文本数据到本地浏览器的传送协议。</div>
<div class="line">HTTPS：以 <strong>安全</strong> 为目标的HTTP。在原有的HTTP下加入了SSL层，SSL加密的主要作用是：</div>
</div>
<ol class="arabic simple">
<li>建立 <strong>信息安全通道</strong> 来保证数据传输的安全；</li>
<li>确认网站的 <strong>真实性</strong>，凡是使用了HTTPS的网站，都可以通过点击浏览器地址栏的锁头标志查看网站认证之后的真实信息；</li>
<li>有的网站虽然使用了HTTPS协议，但是还是会被浏览器显示不安全，是因为给此类网站颁发的CA证书不被CA机构信任。但是此类网站的信息的确也是经过SSL加密的；</li>
<li>在爬取这类不受信的网站时，需要 <strong>设置忽略证书</strong> 的选项，否则会提示SSL链接错误。</li>
</ol>
</div>
<hr class="docutils" />
<div class="section" id="uri-url-urn">
<h2>URI-URL-URN区别<a class="headerlink" href="#uri-url-urn" title="Permalink to this headline">¶</a></h2>
<p>URI [Uniform Resource Identifier]</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">URI的全称为Uniform Resource Identifier，即 <strong>统一资源标志符</strong>。它是一个用于标识某一互联网资源名称的字符串。URI中包含了URL以及URN</p>
</div>
<p>URL [Universal Resource Locator]</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">URI全称为 <strong>统一资源定位符</strong>，URL是URI的一个子集，URL告诉我们访问网络位置的方式。所有的URL都是URI</p>
</div>
<p>URN [Universal Resource Name]</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">URN的全称为 <strong>统一资源名称</strong>，虽然URN在平时用的很少，但并不代表它没有任何意义。相反，它虽然不能够像URL那样给我指定资源的具体位置，但是它却能够唯一的指定资源的名称。例如书籍的ISBN码和产品在系统内的序列号</p>
</div>
<a class="reference internal image-reference" href="_images/diff.png"><img alt="_images/diff.png" src="_images/diff.png" style="width: 200px;" /></a>
<dl class="docutils">
<dt>由上图可以很清晰的看出它们三者的关系：</dt>
<dd>URL类似于住址，它告诉你一种寻找目标的方式。这个定义同时也是一个URI。 相对地，可以把一个人的名字看作是URN；因此可以用URN来唯一标识一个实体。由于可能存在同名的情况，所以更准确地说，人名这个例子并不是十分恰当。更为恰当的是书籍的ISBN码和产品在系统内的序列号，尽管没有告诉你用什么方式或者到什么地方去找到目标，但是你有足够的信息来检索到它。</dd>
</dl>
</div>
<hr class="docutils" />
<div class="section" id="http">
<h2>HTTP的请求过程<a class="headerlink" href="#http" title="Permalink to this headline">¶</a></h2>
<blockquote>
<div>————在浏览器地址栏输入url后到底发生了什么？</div></blockquote>
<p>简单来讲，大致分为以下几步：</p>
<ul class="simple">
<li>在浏览器中输入一个URL并回车</li>
<li>浏览器向此URL所指向网站所在的服务器发送了一个请求</li>
<li>服务器接收到此请求后对请求进行处理和解析</li>
<li>服务器返回对此请求的响应给浏览器</li>
<li>响应里包含了页面的源代码等内容，浏览器对响应内容进行解析并将内容在网页中呈现</li>
</ul>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">此处的浏览器就是本地客户端，上述的过程就是客户端和服务端交互的过程。</p>
</div>
<div class="section" id="request">
<h3>请求 (Request)<a class="headerlink" href="#request" title="Permalink to this headline">¶</a></h3>
<p>请求一般分为以下几个部分：</p>
<blockquote>
<div><strong>1. 请求方法 (Request Method)</strong></div></blockquote>
<p>常见的请求方法有两种：<em>GET</em>、<em>POST</em> ，它们的区别如下：</p>
<p><em>GET</em> 请求中的参数包含在URL里面，<strong>数据可以在URL中看到</strong>。如百度搜索python的 <em>URL</em> 为：<a class="reference external" href="https://www.baidu.com/s?wd=python">https://www.baidu.com/s?wd=python</a> , <em>GET</em> 的参数能够在URL中看到
<em>POST</em> 请求的 <em>URL</em> 不会包含这些数据，<em>POST</em> 的数据都是通过表单形式传输的，其会包含在请求体中。
<em>GET</em> 请求的参数由于是包含在URL中，所以它有最大长度(1024字节)。
而 <em>POST</em> 方式由于表单提交所以没有大小限制在遇到需要提交敏感信息或者是上传大文件时最好采用 <em>POST</em> 方法。</p>
<blockquote>
<div><strong>2. 请求的网址 (Request URL)</strong></div></blockquote>
<p>请求的网址，即URL，它能够唯一确定我们想请求的资源</p>
<blockquote>
<div><strong>3. 请求头 (Request Headers)</strong></div></blockquote>
<ul class="simple">
<li>Accept：请求报头域，用于指定客户端可接受哪些类型的信息</li>
<li>Accept-Language：指定客户端可接受的语言类型</li>
<li>Accept-Encoding：指定客户端可接受的内容编码</li>
<li>Host：用于指定请求资源的主机IP和端口号，其内容为请求URL的原始服务器或网管的位置。</li>
<li>Cookies：网站为了辨别用户进行会话跟踪而存储在用户本地的数据。<em>Cookies</em> 的主要功能是 <strong>维持当前访问会话</strong>。
Cooikes中有信息标识了所对应的服务器的会话，每次浏览器在请求该站点的页面时，都会在请求头中加上Cooikes并将其发送给服务器，
这样服务器才能够通过Cooikes识别出到底是谁。</li>
<li>Referer：标识请求是从哪个页面发出</li>
<li>User-Agent：使服务器识别客户使用的操作系统及版本、浏览器及版本等信息。爬虫时加上此信息可以伪装成浏览器。</li>
<li>Content-Type：表示具体请求中的媒体类型信息。例如text/html表示HTML格式，image/gif表示GIF图片</li>
</ul>
<p>例如登录某些需要用户名和密码的网站，提交这些内容时就会以表单数据的形式提交给服务器。以什么形式提交数据与上述的请求头中的Content-Type
息息相关。</p>
<p class="centered">
<strong>表1.1 Content-Type 和 POST提交数据方式的关系</strong></p><table border="1" class="docutils">
<colgroup>
<col width="65%" />
<col width="35%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">Content-Type</th>
<th class="head">提交数据的方式</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>application/x-www-form-urlencoded</td>
<td>表单数据</td>
</tr>
<tr class="row-odd"><td>application/form-data</td>
<td>表单文件上传</td>
</tr>
<tr class="row-even"><td>application/json</td>
<td>序列化JSON数据</td>
</tr>
<tr class="row-odd"><td>text/xml</td>
<td>XML数据</td>
</tr>
</tbody>
</table>
<blockquote>
<div><strong>4. 请求体 (Request Body)</strong></div></blockquote>
<p>请求体中的内容通常是 <em>POST</em> 请求中的表单数据，而对于 <em>GET</em> 请求，请求体则为空。因为 <em>GET</em> 请求的参数都在 <em>URL</em> 中。</p>
</div>
<div class="section" id="response">
<h3>响应 (Response)<a class="headerlink" href="#response" title="Permalink to this headline">¶</a></h3>
<p>响应由服务器返回给客户端，其可由以下三部分组成：</p>
<blockquote>
<div><ol class="arabic simple">
<li>响应状态码 (Response Status Code)</li>
</ol>
</div></blockquote>
<p>响应状态码表示服务器的响应状态，下表列出了常见多状态码及其说明</p>
<p class="centered">
<strong>表1.2 常见错误状态码及其原因</strong></p><table border="1" class="docutils">
<colgroup>
<col width="8%" />
<col width="26%" />
<col width="66%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">状态码</th>
<th class="head">说 明</th>
<th class="head">详 情</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>200</td>
<td>成功</td>
<td>服务器成功处理了请求</td>
</tr>
<tr class="row-odd"><td>301</td>
<td>永久重定向</td>
<td>请求的网页永久移动到新的位置</td>
</tr>
<tr class="row-even"><td>302</td>
<td>临时重定向</td>
<td>请求的网页暂时跳转到其他页面</td>
</tr>
<tr class="row-odd"><td>403</td>
<td>禁止访问</td>
<td>服务器收到请求但拒绝处理此请求</td>
</tr>
<tr class="row-even"><td>404</td>
<td>页面未找到</td>
<td>服务器找不到请求的页面</td>
</tr>
<tr class="row-odd"><td>500</td>
<td>服务器内部错误</td>
<td>服务器遇到错误，无法完成请求</td>
</tr>
<tr class="row-even"><td>502</td>
<td>错误网关(Bad Gate)</td>
<td>服务器作为网关或代理，从上游服务器收到无效响应</td>
</tr>
<tr class="row-odd"><td>503</td>
<td>服务不可用</td>
<td>服务器目前无法使用</td>
</tr>
<tr class="row-even"><td>504</td>
<td>网关超时</td>
<td>服务器作为网关或代理，没有及时从上游服务器收到请求</td>
</tr>
</tbody>
</table>
<blockquote>
<div><ol class="arabic simple" start="2">
<li>响应头 (Response Headers)</li>
</ol>
</div></blockquote>
<ul class="simple">
<li>Date：标识响应 <strong>产生的时间</strong></li>
<li>Last-Modified：指定资源的 <strong>最后修改时间</strong></li>
<li>Content-Encoding：指定响应内容的 <strong>编码</strong></li>
<li>Server：包含服务器的信息，比如名称、版本号等信息</li>
<li>Content-Type：文档类型，指定返回的数据类型是什么，和请求头中的功能类似</li>
<li>Set-Cookies：响应头中的此内容告诉浏览器需要将此内容放在Cooikes中，下次请求时需携带此Cooikes请求</li>
<li>Expires：指定响应的过期时间，可以使代理服务器或浏览器将加载的内容更新到缓存中，如果再次访问，直接从缓存中加载，降低服务器负载，缩短加载时间</li>
</ul>
<blockquote>
<div><ol class="arabic simple" start="3">
<li>响应体 (Response Body)</li>
</ol>
</div></blockquote>
<p>响应的正文数据都在响应体中，所以最重要的当属响应体中的内容。
爬虫请求网页后要解析的内容就是响应体。可以在浏览器的开发者工具中选择Preview查看响应体的内容</p>
<p>在爬虫时，主要通过响应体得到网页的源代码、JSON数据等。然后从相应的内容提取。</p>
</div>
</div>
<hr class="docutils" />
<div class="section" id="id2">
<h2>网页基础<a class="headerlink" href="#id2" title="Permalink to this headline">¶</a></h2>
<blockquote>
<div>————为什么浏览器的打开网页显示会是这个样子？</div></blockquote>
<div class="section" id="id3">
<h3>网页的组成<a class="headerlink" href="#id3" title="Permalink to this headline">¶</a></h3>
<p>网页可以分为三大部分————HTML、CSS、JS</p>
<ol class="arabic simple">
<li>HTML：HTML语言全称为 Hyper Text Markup Language，即超文本标记语言。网页中的所有元素，基础架构都是HTML。不同类型的元素由不同的标签来表示。正是由于各种标签通过不同的排列和嵌套最后才形成了网页的框架</li>
<li>CSS: CSS全称为 Cascading Style Sheets,即层叠样式表。为什么叫做’层叠’是指当HTML中引用了数个样式文件，并且发生冲突时，浏览器能够依据层叠顺序处理。CSS是目前唯一的网页页面排版样式标准</li>
<li>JS: 全称为JavaScript，是一种脚本语言。它能够给页面提供交互和动画效果。如下载进度条、提示框、轮播图等</li>
</ol>
<p>综上所述，HTML定义了网页的内容和结构，CSS描述的网页的布局，JS定义了网页的行为。如果把网页比作一个人的话，那么HTML就好比是骨架，CSS犹如身上的肌肉和衣服，JS就是描述这个人的行为。</p>
<p>Demo html</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>&lt;!DOCTYPE html&gt;
&lt;html&gt;
  &lt;head&gt;
    &lt;meta charset=&#39;UTF-8&#39;&gt;
    &lt;title&gt;This is a demo web&lt;/title&gt;
  &lt;/head&gt;
  &lt;body&gt;
    &lt;div id=&#39;aa&#39;&gt;
      &lt;div class=&#39;bb&#39;&gt;
        &lt;h2&gt;Hello world!&lt;/h2&gt;
        &lt;p&gt;This is paragraph.&lt;/p&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  &lt;/body&gt;
&lt;/html&gt;
</pre></div>
</div>
<p>上述是一个简单的HTML代码实例。开头用 <code class="docutils literal notranslate"><span class="pre">&lt;!DOCTYPE</span> <span class="pre">html&gt;</span></code> 定义文档的类型为html。其次是最外层需要用 <code class="docutils literal notranslate"><span class="pre">&lt;html&gt;</span></code> 和 <code class="docutils literal notranslate"><span class="pre">&lt;/html&gt;</span></code> 将所有标签包含进来。
同时在内部分别定义了 <code class="docutils literal notranslate"><span class="pre">&lt;head&gt;</span></code> 和 <code class="docutils literal notranslate"><span class="pre">&lt;body&gt;</span></code> 标签。代表网页头和网页体，在网页头中定义了页面的编码方式为 <em>UTF-8</em>，同时给页面设定了一个title。此标题是显示在浏览器的页面选项卡中
除此之外还可以在网页头中引入外部的js文件或者css文件(你也可以在body中引入该文件，好处是网页HTML加载完成后再进行渲染)</p>
<p>此外，在上述代码中的 <code class="docutils literal notranslate"><span class="pre">div</span></code> 标签中还定义了 <code class="docutils literal notranslate"><span class="pre">id</span></code> 和 <code class="docutils literal notranslate"><span class="pre">class</span></code> 。通过 <code class="docutils literal notranslate"><span class="pre">id</span></code> 的值能够唯一的确定页面中的这个 <code class="docutils literal notranslate"><span class="pre">div</span></code> 区块，而 <code class="docutils literal notranslate"><span class="pre">class</span></code> 的值则是能确定一类名称一致的区块。灵活配合CSS能够设定区块的样式。</p>
<dl class="docutils">
<dt>更多前端知识建议参考：</dt>
<dd><a class="reference external" href="https://www.w3.org/community/webed/wiki/HTML/Training">W3C-HTML教程</a> 、 <a class="reference external" href="https://developer.mozilla.org/zh-CN/docs/Learn/HTML">MDN-HTML教程</a></dd>
</dl>
</div>
<div class="section" id="html-dom">
<h3>HTML DOM<a class="headerlink" href="#html-dom" title="Permalink to this headline">¶</a></h3>
<p>在HTML中，所有的标签定义的内容都是节点，它们共同构成了一个HTML DOM树型结构。如下所示：</p>
<img alt="_images/html_dom.gif" src="_images/html_dom.gif" />
<p>在理解之前首先要知道什么是DOM？</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p>DOM(Document Object Model),即文档对象模型。</p>
<dl class="last docutils">
<dt>DOM 是 W3C（万维网联盟）的标准，它定义了访问 HTML 和 XML 文档的标准：</dt>
<dd>W3C 文档对象模型(DOM)是中立于 <strong>平台</strong> 和 <strong>语言</strong> 的接口，它允许 <strong>程序</strong> 和 <strong>脚本</strong> 动态地访问和更新文档的内容、结构和样式。</dd>
<dt>W3C DOM 标准被分为 3 个不同的部分：</dt>
<dd><ol class="first last arabic simple">
<li>核心 DOM —— 针对任何结构化文档的标准模型</li>
<li>XML DOM —— 针对 XML 文档的标准模型</li>
<li>HTML DOM —— 针对 HTML 文档的标准模型</li>
</ol>
</dd>
</dl>
</div>
<p>通过HTML DOM,上图中的所有节点都可以通过JavaScript访问。所有的节点元素均可被修改、创建和删除。
同时节点与节点之间还具有层级关系：</p>
<blockquote>
<div><ol class="arabic simple">
<li>父节点 —— 父节点拥有子节点</li>
<li>子节点 —— 任何除根节点外的节点都是其上级节点的子节点</li>
<li>兄弟节点 ——— 同级节点称为兄弟节点</li>
</ol>
</div></blockquote>
</div>
<div class="section" id="css">
<h3>CSS选择器<a class="headerlink" href="#css" title="Permalink to this headline">¶</a></h3>
<p>网页是由一个一个节点构成的，CSS选择器会根据不同的节点设置不同的样式规则。</p>
<p class="centered">
<strong>表1.3 部分CSS选择器定位规则</strong></p><table border="1" class="docutils">
<colgroup>
<col width="15%" />
<col width="25%" />
<col width="59%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">选择器</th>
<th class="head">例 子</th>
<th class="head">描 述</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td><code class="docutils literal notranslate"><span class="pre">.</span></code></td>
<td><code class="docutils literal notranslate"><span class="pre">.abc</span></code></td>
<td>选择 <em>class=’abc’</em> 的所有节点</td>
</tr>
<tr class="row-odd"><td><code class="docutils literal notranslate"><span class="pre">.</span></code></td>
<td><code class="docutils literal notranslate"><span class="pre">div</span> <span class="pre">.abc</span></code></td>
<td>选择 <em>class=’abc’</em> 的所有名为div的节点</td>
</tr>
<tr class="row-even"><td><code class="docutils literal notranslate"><span class="pre">#</span></code></td>
<td><code class="docutils literal notranslate"><span class="pre">#abc</span></code></td>
<td>选择 <em>id=’abc’</em> 的所有节点</td>
</tr>
<tr class="row-odd"><td><code class="docutils literal notranslate"><span class="pre">*</span></code></td>
<td><code class="docutils literal notranslate"><span class="pre">*</span></code></td>
<td>选择所有节点</td>
</tr>
<tr class="row-even"><td>空</td>
<td><code class="docutils literal notranslate"><span class="pre">p</span></code></td>
<td>选择所有的p节点</td>
</tr>
<tr class="row-odd"><td>空,空</td>
<td><code class="docutils literal notranslate"><span class="pre">div,p</span></code></td>
<td>选择所有的div节点和的p节点</td>
</tr>
<tr class="row-even"><td>空 空</td>
<td><code class="docutils literal notranslate"><span class="pre">div</span> <span class="pre">p</span></code></td>
<td>选择所有的div节点中的p节点</td>
</tr>
<tr class="row-odd"><td>空&gt;空</td>
<td><code class="docutils literal notranslate"><span class="pre">div&gt;p</span></code></td>
<td>选择所有父节点为div节点的p节点</td>
</tr>
<tr class="row-even"><td>空+空</td>
<td><code class="docutils literal notranslate"><span class="pre">div+p</span></code></td>
<td>选择所有紧接着&lt;div&gt;节点之后的&lt;p&gt;节点</td>
</tr>
<tr class="row-odd"><td>[属性]</td>
<td><code class="docutils literal notranslate"><span class="pre">[target]</span></code></td>
<td>选择所有带有target属性的节点</td>
</tr>
</tbody>
</table>
<blockquote>
<div>————全部CSS选择器表请参考 <a class="reference external" href="http://www.w3school.com.cn/cssref/css_selectors.ASP">CSS选择器参考手册</a></div></blockquote>
</div>
</div>
<hr class="docutils" />
<div class="section" id="id5">
<h2>爬虫的基本原理<a class="headerlink" href="#id5" title="Permalink to this headline">¶</a></h2>
<p>正如前述所说，互联网就好比一张铺开的大网。各种信息交织在一起。爬虫便是能够自动的将我们所需要的信息快速且高效的抓取下来</p>
<div class="section" id="id6">
<h3>爬虫的步骤<a class="headerlink" href="#id6" title="Permalink to this headline">¶</a></h3>
<p><strong>1. 获取网页</strong></p>
<blockquote>
<div>这是爬虫首先要做的事情————获取网页的源代码。向URL网页所在的服务器发送一个请求，返回的响应体便是网页的源代码。
爬虫就是利用这个过程，构造一个请求发送给服务器，然后接收到响应并将其解析。</div></blockquote>
<p>如何用Python实现：</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">在python中提供了很多库来帮助我们实现上述操作，如：urllib、request等。
我们可以利用这些库实现HTTP的请求操作。请求和响应的接收都有库帮助我们完成。
最后通过特定的方法获取到网页的源代码，这样就能够通过程序的手段实现获取网页的过程。</p>
</div>
<div class="admonition warning">
<p class="first admonition-title">Warning</p>
<p class="last">有时利用urllib、request抓取网页时，获得的源代码和实际在浏览器中的看到的不一样。这是由于网页越来越多的利用Ajax异步刷新、前端模块化工具来构建，
整个网页可能都是由JS渲染出来的。此时HTML代码完全就是一个空壳，所有的内容都是由JavaScript去执行HTML代码中引入的JS文件运行得到的。针对此类情况就可以通过分析其后台的Ajax接口，
或是利用Selenium、Splash这样的库来实现模拟JavaScript渲染。</p>
</div>
<p><strong>2. 提取信息</strong></p>
<blockquote>
<div><p>获取到网页源代码后就是分析源代码，定位并提取到我们需要的信息。由于源代码中除了含有我们所需的信息外还含有HTML标签元素等干扰项，通用的办法是利用正则表达式，但是正则表达式在构造时容易出错，且比较复杂。</p>
<p>别急，Python提供了一些库来帮助我们，比如：Beautiful Soup、pyquery、lxml等。使用这些库能够使我们快速地从中提取网页信息，如节点的属性，文本值等。
python的魅力正是如此，如此丰富的武器库能够让我们达到快速开发的目的。</p>
</div></blockquote>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">提取信息是爬虫中十分重要的步骤，它能够使杂乱无章的数据变的条理清晰</p>
</div>
<p><strong>3. 保存数据</strong></p>
<blockquote>
<div><dl class="docutils">
<dt>提取到信息后，通常会将信息保存到某处以便后续使用。保存的形式有很多：</dt>
<dd><ul class="first last simple">
<li>简单保存为TXT文本或JSON文本</li>
<li>保存到数据库中</li>
<li>保存到远程服务器</li>
<li>…</li>
</ul>
</dd>
</dl>
</div></blockquote>
<p><strong>4. 自动化程序</strong></p>
<blockquote>
<div><p>自动化获取信息就是我们爬虫的终极目标，虽然能够用人工的方法获取到信息，但是由于信息量的枯燥和繁杂，就需要借助到自动化程序能够帮助我们完成此类工作</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">我们可以在程序中添加各种异常处理，错误重试，反爬等操作，使爬取能够高效的完成预期工作。</p>
</div>
</div></blockquote>
</div>
</div>
<hr class="docutils" />
<div class="section" id="sessioncookies">
<h2>Session和Cookies<a class="headerlink" href="#sessioncookies" title="Permalink to this headline">¶</a></h2>
<blockquote>
<div><p>————在浏览网站的过程中，经常会遇到需要登录的时候，有的网站甚至只有登录后才能够访问，在登陆后我们可以连续访问很多次网站。但是再过一段时间就需要再次登录才能访问。这是为什么呢？</p>
<p>在此之前，还需要了解一下其他的知识，这样能够方便理解Session和Cookies</p>
</div></blockquote>
<div class="section" id="id7">
<h3>静态网页与动态网页<a class="headerlink" href="#id7" title="Permalink to this headline">¶</a></h3>
<blockquote>
<div><ul class="simple">
<li>静态网页 —— 内容已经被写死的网页，优点是加载速度快，编写简单；缺点是可维护性差，不能根据URL灵活地显示内容。</li>
<li>动态网页 —— 动态解析URL中的参数并与数据库交互，用户的登录和注册操作就是依据动态网站来实现的</li>
</ul>
</div></blockquote>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">在上面提到的登录操作，就是在用户登录后拿到了能够唯一对应该用户的凭证。这样才能够在登录后的一段时间里保持用户的登录状态。
不过这个凭证到底是什么？其实它就是Session和Cookies共同产生的结果!</p>
</div>
</div>
<div class="section" id="id8">
<h3>Session和Cookies原理<a class="headerlink" href="#id8" title="Permalink to this headline">¶</a></h3>
<p>在了解其原理之前，我们必须知道HTTP的一个特点——HTTP的无状态</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">HTTP的无状态是指HTTP协议对事务处理是没有记忆的，服务器不知道客户端是什么状态。每一次向服务器发送请求，服务器收到请求并解析再返回对应的响应，这整个过程是完全独立的。
服务器不会记录前后状态的变化。</p>
</div>
<p>这意味着 <strong>如果后续需要处理前面的信息，则必须重传</strong> 。但是这样重复性的工作肯定不是我想要的。</p>
<dl class="docutils">
<dt>因此，Session(会话)和Cookies这两个用于保持HTTP连接状态的技术就应运而生了。</dt>
<dd><ol class="first last arabic simple">
<li>Session在服务端，用来保存用户的会话信息</li>
<li>Cookies在客户端，在发送请求时被附带上，用来识别用户身份</li>
</ol>
</dd>
</dl>
<p>正是由于这两个技术的存在，才使得我们能够在登录到某一网站后继续访问网站的其他页面而不需要再次验证登录</p>
<p>什么是Session(会话)：</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p>会话本是指 <strong>有始有终</strong> 的一系列动作或消息。例如：街上的两人从刚碰头聊天到刚结束分开这个过程就可以理解为一个会话。</p>
<p class="last">在web中，会话对象(Session)用来存储特定用户所需的属性以及配置信息。这样，当某个用户在网站的web之间跳转时，存储在会话中的变量并不会丢失，而是在整个用户会话中一直存在下去。当用户请求某网站的web时还没有会话，这服务器将自动给用户创建一个会话对象。当会话过期或被放弃后则终止此对话。</p>
</div>
<p>什么是Cookies：</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Cookies是浏览器储存在用户电脑上的一小段文本文件。一个WEB页面或服务器，来告知浏览器按照一定规范来储存这些信息，并在随后的请求中将这些信息发送至服务器。</p>
</div>
<p>Cookie通常用来识别不同的用户。</p>
</div>
<div class="section" id="id9">
<h3>会话维持<a class="headerlink" href="#id9" title="Permalink to this headline">¶</a></h3>
<dl class="docutils">
<dt>如何利用Session和Cookies来保持状态呢？</dt>
<dd><p class="first">当客户端 <strong>第一次</strong> 向服务器发出请求时，服务器会在响应头中返回一个Set-Cookies字段给客户端，此Cooikes用来标记用户身份。客户端会将Cooikes保存起来。当客户端下一次再次请求该网站时会把此Cooikes放到请求头(Request-Headers)中一起提交给服务器。</p>
<p class="last">由于Cooikes中携带了会话ID信息，那么服务器就可以通过Cooikes找到对应的Session所在，然后再判断会话的信息来辨认用户的状态。
反之，如果客户端传给服务器的Cooikes是无效的或者Session已过期了。我们将不能够继续访问此网站，而需要重新登录。</p>
</dd>
</dl>
<p>综上，只有Cooikes和Session相互配合，一个处于客户端(Cooikes)，一个处于服务端(Session)，二者共同协作，就能够实现会话控制。</p>
</div>
<div class="section" id="cooikes">
<h3>Cooikes属性结构<a class="headerlink" href="#cooikes" title="Permalink to this headline">¶</a></h3>
<blockquote>
<div><dl class="docutils">
<dt>Cooikes具有以下几个属性：</dt>
<dd><ol class="first last arabic simple">
<li>Name —— Cooikes的名称，一旦创建不可修改</li>
<li>Value —— Cooikes值，如果值为Unicode字符，则需要为字符编码。如果值为二进制数据，则需要使用BASE64编码</li>
<li>Domain —— 可以访问该Cooikes的域名。</li>
<li>Max Age —— Cooikes失效时间，单位为秒。常和Expires一起使用，通过它可以计算出其有效时间。如果Max Age值为正数则为失效秒数，如果为负数则表示关闭浏览器时Cooikes即失效。</li>
<li>Path —— Cooikes的使用路径，如果设置为/Path/，则只有在路径为/Path/下的页面可以访问该Cooikes，如果设置为/，则本域名下的所有页面都能够访问该Cooikes</li>
<li>Size —— Cooikes的大小</li>
<li>HTTP字段 —— Cooikes的httponly属性。如果此属性为True，则只能在HTTP协议头中会带有此Cooikes的信息，而不能通过document.cooike 来访问此Cooikes</li>
<li>Secure —— 该Cooikes是否仅被使用安全协议传输。此字段默认为False</li>
</ol>
</dd>
</dl>
</div></blockquote>
<p><a class="reference external" href="https://zhuanlan.zhihu.com/p/27669892">SessionCooikes知识参考</a></p>
</div>
<div class="section" id="cooikescooikes">
<h3>会话Cooikes和持久Cooikes<a class="headerlink" href="#cooikescooikes" title="Permalink to this headline">¶</a></h3>
<p>对于Cooikes是否是会话还是持久没有什么严格的区分，都是由上述讲到的Cooikes的Max Age属性决定的。</p>
<dl class="docutils">
<dt>做一个概念上的区分：</dt>
<dd><ol class="first last arabic simple">
<li>会话Cooikes：是指将Cooikes放在浏览器的内存中，浏览器关闭后该Cooikes即失效</li>
<li>持久Cooikes：是指将Cooikes放在客户端的硬盘里，下次打开浏览器还可以继续使用</li>
</ol>
</dd>
</dl>
<p>关于会话Cooikes引起的一个误区：</p>
<div class="admonition warning">
<p class="first admonition-title">Warning</p>
<p>经常有一个说法认为：如果浏览器关闭了那么服务端的会话Session就消失了。</p>
<p>其实这种说法是错误的，在我们关闭浏览器的时候，服务端并不知道我们关闭了浏览器，所以服务端也没有理由删除Session。
但事实上我们遇到的情况确实是关闭浏览器再打开某个网站还是要求用户再次登录，给大家造成这种错觉的罪魁祸首就是会话Cooikes，
因为会话Cooikes是放在浏览器缓存中的，而Cooikes中又保存了Session ID的信息。所以用户关闭了浏览器，相当于丢失了自己的Session ID。
所以服务器没有Session ID，自然找不到对应的Session。故而再次打开还需要让用户登录。</p>
<p class="last">综上，并不是服务端的过错，而是会话Cooikes造成的！！</p>
</div>
</div>
</div>
<div class="section" id="id10">
<h2>代理<a class="headerlink" href="#id10" title="Permalink to this headline">¶</a></h2>
<p>当我们在爬取某些网页时，一开始能够成功爬取到内容。可是过一段时间就出现了错误，网页可能显示‘您的IP访问频率过高，已禁止访问’
这是网站的一种反爬手段，服务器如果检测到某一个IP在单位时间内请求次数超过设定的阈值时，就会直接拒绝服务。
解决这种问题的常用手段就是代理。</p>
<div class="section" id="id11">
<h3>什么是代理<a class="headerlink" href="#id11" title="Permalink to this headline">¶</a></h3>
<blockquote>
<div>代理全称为 <strong>代理服务器</strong> （proxy server），它的功能是帮助用户去获得网络信息。简单来讲就是在以前用户和服务器之间的桥梁中加入了一种代理服务器。
类似于网络信息的中转站，这样的好处是向服务器发送请求的就不再是用户本身，而是代理的服务器了。这样服务端就只能识别到代理的IP，而我们自身的IP得到的隐藏。</div></blockquote>
</div>
<div class="section" id="id12">
<h3>代理的作用<a class="headerlink" href="#id12" title="Permalink to this headline">¶</a></h3>
<p>代理的作用远不止上面讲的伪装IP，其实它还有其他作用</p>
<blockquote>
<div><ol class="arabic simple">
<li>突破自身IP限制，访问一些平时不能访问的站点：比如VPN就是依靠这种技术</li>
<li>访问一些单位或者团体的内部资源：比如教育网的地址段免费代理服务器，就可以用于教育网开发的各类FTP下载上传</li>
<li>提高访问速度：通常代理服务器都设置了较大的硬盘缓冲区，当外界信息通过时，先由代理服务器保存到缓存中，当其他用户也访问到相同的信息时，直接由代理服务器的缓存中取出信息即可</li>
<li>隐藏真实IP：这也是上面说到的，爬虫的时候使用代理就是为了防止IP被封锁，通过是利用由很多代理服务器构成的代理池进行信息的爬取</li>
</ol>
</div></blockquote>
</div>
<div class="section" id="id13">
<h3>代理分类<a class="headerlink" href="#id13" title="Permalink to this headline">¶</a></h3>
<div class="section" id="id14">
<h4>根据协议分类<a class="headerlink" href="#id14" title="Permalink to this headline">¶</a></h4>
<blockquote>
<div><ol class="arabic simple">
<li>FTP 代理服务器：主要用于访问FTP服务器，有上传、下载以及缓存功能，端口一般为21,2121等</li>
<li>HTTP 代理服务器：主要用于访问网页，一般有内容过滤和缓存功能，端口一般为80,8080,3128等</li>
<li>SSL/TLS 代理服务器：主要用于访问加密网站，一般有SSL和TLS加密功能，端口一般为443</li>
<li>RTSP 代理服务器：主要用于访问Real流媒体服务器，一般有缓存功能，端口一般为554</li>
<li>Telnet 代理服务器：主要用于Telnet远程控制，端口一般为23</li>
<li>POP3/SMTP 代理服务器：主要用于收发邮件，一般有缓存功能，端口为110/25</li>
<li>SOCKS 代理服务器：单纯的传输数据包，不关心具体协议的用法，速度很快，有缓存功能，端口一般为1080</li>
</ol>
</div></blockquote>
</div>
<div class="section" id="id15">
<h4>根据匿名程度分类<a class="headerlink" href="#id15" title="Permalink to this headline">¶</a></h4>
<blockquote>
<div><ol class="arabic simple">
<li>高度匿名代理：会将数据包原封不动的转发，在服务端看来就是一个普通的客户端在访问，服务端记录的IP就是代理服务器的IP</li>
<li>普通匿名代理：会在数据包上做一些改动，服务端可能会发现这是代理服务器，甚至追查到客户端的真实IP</li>
<li>透明代理：不但改动数据包，并且会告诉服务器客户端的真实IP</li>
<li>间谍代理：组织或个人创建的用于记录用户传输的数据，然后进行研究、监控等目的的代理</li>
</ol>
</div></blockquote>
</div>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
      
        <a href="forword.html" class="btn btn-neutral" title="0. 写在前面" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2018, adapt

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script type="text/javascript" src="_static/jquery.js"></script>
        <script type="text/javascript" src="_static/underscore.js"></script>
        <script type="text/javascript" src="_static/doctools.js"></script>
        <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    

  

  <script type="text/javascript" src="_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>