
======================
1. 爬虫基础
======================

.. note::
   
   如果把互联网比作成一张大网，那么爬虫就是获取到网页提取并保存其中的信息的自动化 **程序** 。
在认识爬虫之前，还需要具备的一些基础的网络知识。

------------

HTTP和HTTPS
========================

在浏览器中网页的url开头中经常会见到http或者https。
http和https都是访问资源时需要的 **协议类型**，除此之外还有一些其他协议如：ftp、sftp、smb等

| HTTP：**超文本传输协议**。顾名思义，此协议是从网络传输超文本数据到本地浏览器的传送协议。
| HTTPS：以 **安全** 为目标的HTTP。在原有的HTTP下加入了SSL层，SSL加密的主要作用是：

1. 建立 **信息安全通道** 来保证数据传输的安全；
#. 确认网站的 **真实性**，凡是使用了HTTPS的网站，都可以通过点击浏览器地址栏的锁头标志查看网站认证之后的真实信息；
#. 有的网站虽然使用了HTTPS协议，但是还是会被浏览器显示不安全，是因为给此类网站颁发的CA证书不被CA机构信任。但是此类网站的信息的确也是经过SSL加密的；
#. 在爬取这类不受信的网站时，需要 **设置忽略证书** 的选项，否则会提示SSL链接错误。

URI-URL-URN区别
========================

URI [Uniform Resource Identifier]

.. note::
   
   URI的全称为Uniform Resource Identifier，即 **统一资源标志符**。它是一个用于标识某一互联网资源名称的字符串。URI中包含了URL以及URN

URL [Universal Resource Locator]

.. note::
   
   URI全称为 **统一资源定位符**，URL是URI的一个子集，URL告诉我们访问网络位置的方式。所有的URL都是URI

URN [Universal Resource Name]

.. note::

   URN的全称为 **统一资源名称**，虽然URN在平时用的很少，但并不代表它没有任何意义。相反，它虽然不能够像URL那样给我指定资源的具体位置，但是它却能够唯一的指定资源的名称。例如书籍的ISBN码和产品在系统内的序列号

.. image:: ./diff.png
  :width: 200px

由上图可以很清晰的看出它们三者的关系：
    URL类似于住址，它告诉你一种寻找目标的方式。这个定义同时也是一个URI。 相对地，可以把一个人的名字看作是URN；因此可以用URN来唯一标识一个实体。由于可能存在同名的情况，所以更准确地说，人名这个例子并不是十分恰当。更为恰当的是书籍的ISBN码和产品在系统内的序列号，尽管没有告诉你用什么方式或者到什么地方去找到目标，但是你有足够的信息来检索到它。


HTTP的请求过程
========================

  ————在浏览器地址栏输入url后到底发生了什么？

简单来讲，大致分为以下几步：

+ 在浏览器中输入一个URL并回车
+ 浏览器向此URL所指向网站所在的服务器发送了一个请求
+ 服务器接收到此请求后对请求进行处理和解析
+ 服务器返回对此请求的响应给浏览器
+ 响应里包含了页面的源代码等内容，浏览器对响应内容进行解析并将内容在网页中呈现

.. note::
   此处的浏览器就是本地客户端，上述的过程就是客户端和服务端交互的过程。

请求 (Request)
------------------------

请求一般分为以下几个部分：

 **1. 请求方法 (Request Method)**

常见的请求方法有两种：*GET*、*POST* ，它们的区别如下：

*GET* 请求中的参数包含在URL里面，**数据可以在URL中看到**。\
如百度搜索python的 *URL* 为：https://www.baidu.com/s?wd=python , *GET* 的参数能够在URL中看到
*POST* 请求的 *URL* 不会包含这些数据，*POST* 的数据都是通过表单形式传输的，其会包含在请求体中。
*GET* 请求的参数由于是包含在URL中，所以它有最大长度(1024字节)。
而 *POST* 方式由于表单提交所以没有大小限制在遇到需要提交敏感信息或者是上传大文件时最好采用 *POST* 方法。

 **2. 请求的网址 (Request URL)**

请求的网址，即URL，它能够唯一确定我们想请求的资源

 **3. 请求头 (Request Headers)**

+ Accept：请求报头域，用于指定客户端可接受哪些类型的信息
+ Accept-Language：指定客户端可接受的语言类型
+ Accept-Encoding：指定客户端可接受的内容编码
+ Host：用于指定请求资源的主机IP和端口号，其内容为请求URL的原始服务器或网管的位置。
+ Cookies：网站为了辨别用户进行会话跟踪而存储在用户本地的数据。*Cookies* 的主要功能是 **维持当前访问会话**。
  Cooikes中有信息标识了所对应的服务器的会话，每次浏览器在请求该站点的页面时，都会在请求头中加上Cooikes并将其发送给服务器，
  这样服务器才能够通过Cooikes识别出到底是谁。
+ Referer：标识请求是从哪个页面发出
+ User-Agent：使服务器识别客户使用的操作系统及版本、浏览器及版本等信息。爬虫时加上此信息可以伪装成浏览器。
+ Content-Type：表示具体请求中的媒体类型信息。例如text/html表示HTML格式，image/gif表示GIF图片

例如登录某些需要用户名和密码的网站，提交这些内容时就会以表单数据的形式提交给服务器。以什么形式提交数据与上述的请求头中的Content-Type
息息相关。

.. centered:: 表1.1 Content-Type 和 POST提交数据方式的关系
===================================== ====================
Content-Type                          提交数据的方式
===================================== ====================
application/x-www-form-urlencoded     表单数据
application/form-data                 表单文件上传
application/json                      序列化JSON数据
text/xml                              XML数据
===================================== ====================

 **4. 请求体 (Request Body)**

请求体中的内容通常是 *POST* 请求中的表单数据，而对于 *GET* 请求，请求体则为空。因为 *GET* 请求的参数都在 *URL* 中。


响应 (Response)
------------------------

响应由服务器返回给客户端，其可由以下三部分组成：

 1. 响应状态码 (Response Status Code)

响应状态码表示服务器的响应状态，下表列出了常见多状态码及其说明

.. centered:: 表1.2 常见错误状态码及其原因
====== ==================== ===============================================
状态码  说 明                详 情
====== ==================== ===============================================
200    成功                  服务器成功处理了请求
301    永久重定向            请求的网页永久移动到新的位置
302    临时重定向            请求的网页暂时跳转到其他页面
403    禁止访问              服务器收到请求但拒绝处理此请求
404    页面未找到            服务器找不到请求的页面
500    服务器内部错误        服务器遇到错误，无法完成请求
502    错误网关(Bad Gate)    服务器作为网关或代理，从上游服务器收到无效响应
503    服务不可用            服务器目前无法使用             
504    网关超时              服务器作为网关或代理，没有及时从上游服务器收到请求
====== ==================== ===============================================

 2. 响应头 (Response Headers)

+ Date：标识响应 **产生的时间**
+ Last-Modified：指定资源的 **最后修改时间**
+ Content-Encoding：指定响应内容的 **编码**
+ Server：包含服务器的信息，比如名称、版本号等信息
+ Content-Type：文档类型，指定返回的数据类型是什么，和请求头中的功能类似
+ Set-Cookies：响应头中的此内容告诉浏览器需要将此内容放在Cooikes中，下次请求时需携带此Cooikes请求
+ Expires：指定响应的过期时间，可以使代理服务器或浏览器将加载的内容更新到缓存中，如果再次访问，直接从缓存中加载，降低服务器负载，缩短加载时间

 3. 响应体 (Response Body)

响应的正文数据都在响应体中，所以最重要的当属响应体中的内容。
爬虫请求网页后要解析的内容就是响应体。

在爬虫时，主要通过响应体得到网页的源代码、JSON数据等。然后从相应的内容提取。
